llm:
  host: llm.hnatekmar.dev
  vllm:
    image: vllm/vllm-openai:latest
  llama_cpp:
    image: ghcr.io/ggml-org/llama.cpp:server-cuda

ingress:
  host: llama.hnatekmar.dev

models:
  - name: qwen2.5-coder # exl2 example
    engine: aphrodite
    replicas: 1
    resources:
      requests:
        nvidia.com/gpu: 2
      limits:
        nvidia.com/gpu: 2
    args:
      - run
      - /models/exl2/Qwen2.5-Coder-32B-Instruct-exl2
  - name: qwen3
    args:
      - --jinja
      - "-m"
      - "/models/gguf/Qwen3-32B-Q5_K_M.gguf"
      - "-ngl"
      - "99"
    selector: {}
    replicas: 3
    resources:
      requests:
        nvidia.com/gpu: 1
      limits:
        nvidia.com/gpu: 1
  - name: qwen3
    args:
      - --jinja
      - "-m"
      - "/models/gguf/Qwen3-32B-Q5_K_M.gguf"
      - "-ngl"
      - "99"
    selector: {}
    resources:
      requests:
        nvidia.com/gpu: 1
      limits:
        nvidia.com/gpu: 1
